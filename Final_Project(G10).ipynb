{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gourango Modak , 18-37102-1\n",
    "# Shuvra Smaran Das , 18-37161-1\n",
    "# Md.Salimullah , 18-37161-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "**In our daily life, it is easy for us to determine whether or not a natural picture is being rotated. But it may be hard for computers to pridict human level output. So, we are going to pridict rotation angle of a given image [0, 90, 180, 270].**\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**The database contains 67 Indoor categories, and a total of 15620 images. The number of images varies across categories, but there are at least 100 images per category. All images are in jpg format.**\n",
    "\n",
    "\n",
    "**From this dataset we randomly pick an image and rotate it into these [ 0, 90, 180, 270 ] any random rotation and build our custom dataset.**\n",
    "\n",
    "[Dataset Link](https://www.kaggle.com/itsahmad/indoor-scenes-cvpr-2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mAoyLtajDXBs"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import imutils\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import h5py\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPool2D, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure setting\n",
    "\n",
    "# initialize dataset and rotationed dataset location\n",
    "dataset_path = \"H:\\CVPR project\\Dataset\\indoorCVPR_09\\Images\"\n",
    "rotated_path = \"H:\\CVPR project\\Rotationed_Images\"\n",
    "\n",
    "# HDF5 dataset store location\n",
    "hdf5_path = \"H:\\CVPR project\\Hdf5\\correcting_rotation_dataset.hdf5\"\n",
    "model_path=\"H:\\CVPR project\\Model\\orientation_correction_classifier.cpickle\"\n",
    "\n",
    "# initialize vgg16 weight path location\n",
    "weight_path = r\"H:\\CVPR project\\Weight\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# initialize batch size and buffer size\n",
    "batch_size = 32\n",
    "buffer_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVhWzYMnaeAg",
    "outputId": "72a3ce15-a395-47ae-a888-8cce716eb4dd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Dataset: 100% |########################################| Time: 0:06:00\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] angle=0: 2,499\n",
      "[INFO] angle=90: 2,480\n",
      "[INFO] angle=180: 2,506\n",
      "[INFO] angle=270: 2,493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# here we take 10k images from total images and shuffle the images\n",
    "imagePaths = list(paths.list_images(dataset_path))[:10000]\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# initialize a dictionary to keep track of the number of each angle\n",
    "angles = {}\n",
    "widgets = [\"Building Dataset: \", progressbar.Percentage(), \" \",progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=len(imagePaths),widgets=widgets).start()\n",
    "\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    \n",
    "    # determine the rotation angle, and load the image\n",
    "    angle = np.random.choice([0, 90, 180, 270])\n",
    "    image = cv2.imread(imagePath)\n",
    "\n",
    "    # if the image is None\n",
    "    if image is None:\n",
    "        continue\n",
    "    \n",
    "    # rotate the image based on the selected angle, then construct\n",
    "    # the path to the base output directory\n",
    "    image = imutils.rotate_bound(image, angle)\n",
    "    base = os.path.sep.join([rotated_path, str(angle)])\n",
    "\n",
    "    # if the base path does not exist already, create it\n",
    "    if not os.path.exists(base):\n",
    "        os.makedirs(base)\n",
    "\n",
    "    # extract the image file extension, then construct the full path\n",
    "    # to the output file\n",
    "    ext = imagePath[imagePath.rfind(\".\"):]\n",
    "    outputPath = [base, \"image_{}{}\".format(str(angles.get(angle, 0)).zfill(5), ext)]\n",
    "    outputPath = os.path.sep.join(outputPath)\n",
    "\n",
    "    # save the image\n",
    "    cv2.imwrite(outputPath, image)\n",
    "    # update the count for the angle\n",
    "    c = angles.get(angle, 0)\n",
    "    angles[angle] = c + 1\n",
    "    pbar.update(i)\n",
    "\n",
    "\n",
    "# finish the progress bar\n",
    "pbar.finish()\n",
    "\n",
    "# loop over the angles and display counts for each of them\n",
    "for angle in sorted(angles.keys()):\n",
    "    print(\"[INFO] angle={}: {:,}\".format(angle, angles[angle]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "NXlvGuCKT3p7"
   },
   "outputs": [],
   "source": [
    "# we used this class to store all images into hdf5 file format.\n",
    "class HDF5DatasetWriter:\n",
    "    \n",
    "    def __init__(self, dims, outputPath, dataKey=\"images\", bufSize=1000):\n",
    "    # check to see if the output path exists, and if so, raise\n",
    "    # an exception\n",
    "        if os.path.exists(outputPath):\n",
    "            raise ValueError(\"The supplied ‘outputPath‘ already \"\n",
    "             \"exists and cannot be overwritten. Manually delete \"\n",
    "            \"the file before continuing.\", outputPath)\n",
    "        \n",
    "        # open the HDF5 database for writing and create two datasets:\n",
    "        # one to store the images/features and another to store the\n",
    "        # class labels\n",
    "        self.db = h5py.File(outputPath, \"w\")\n",
    "        self.data = self.db.create_dataset(dataKey, dims,\n",
    "        dtype=\"float\")\n",
    "        self.labels = self.db.create_dataset(\"labels\", (dims[0],),\n",
    "        dtype=\"int\")\n",
    "        \n",
    "        # store the buffer size, then initialize the buffer itself\n",
    "        # along with the index into the datasets\n",
    "        self.bufSize = bufSize\n",
    "        self.buffer = {\"data\": [], \"labels\": []}\n",
    "        self.idx = 0\n",
    "    \n",
    "    def add(self, rows, labels):\n",
    "        # add the rows and labels to the buffer\n",
    "        self.buffer[\"data\"].extend(rows)\n",
    "        self.buffer[\"labels\"].extend(labels)\n",
    "        # check to see if the buffer needs to be flushed to disk\n",
    "        if len(self.buffer[\"data\"]) >= self.bufSize:\n",
    "            self.flush()\n",
    "    \n",
    "    def flush(self):\n",
    "        # write the buffers to disk then reset the buffer\n",
    "        i = self.idx + len(self.buffer[\"data\"])\n",
    "        self.data[self.idx:i] = self.buffer[\"data\"]\n",
    "        self.labels[self.idx:i] = self.buffer[\"labels\"]\n",
    "        self.idx = i\n",
    "        self.buffer = {\"data\": [], \"labels\": []}\n",
    "    \n",
    "    def storeClassLabels(self, classLabels):\n",
    "        # create a dataset to store the actual class label names,\n",
    "        # then store the class labels\n",
    "        dt = h5py.special_dtype(vlen=str)\n",
    "        labelSet = self.db.create_dataset(\"label_names\",(len(classLabels),), dtype=dt)\n",
    "        labelSet[:] = classLabels\n",
    "\n",
    "    def close(self):\n",
    "        # check to see if there are any other entries in the buffer\n",
    "        # that need to be flushed to disk\n",
    "        if len(self.buffer[\"data\"]) > 0:\n",
    "            self.flush()\n",
    "\n",
    "        # close the dataset\n",
    "        self.db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "## VGG 16\n",
    "\n",
    "\n",
    "![title](pic/vgg16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet_16:\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(weights_path=None):\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
    "        \n",
    "        model.add(Flatten(name='flatten'))\n",
    "\n",
    "        if weights_path:\n",
    "            model.load_weights(weights_path)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "vgg16 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=VGGNet_16.build(weight_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UxA8mKzFpJG",
    "outputId": "6034a88c-b04e-4633-9b41-62b9c724ae65",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   0% |                                    | ETA:  --:--:--\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100% |#####################################| Time: 0:35:53\n"
     ]
    }
   ],
   "source": [
    "# initlize the batch size\n",
    "bs = batch_size\n",
    "\n",
    "# array slicing during training time\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(rotated_path))\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# load the VGG16 network\n",
    "# print(\"[INFO] loading network...\")\n",
    "# model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# initialize the HDF5 dataset writer, then store the class label\n",
    "# names in the dataset\n",
    "dataset = HDF5DatasetWriter((len(imagePaths), 512 * 7 * 7), hdf5_path, dataKey=\"features\", bufSize=buffer_size)\n",
    "\n",
    "dataset.storeClassLabels(le.classes_)\n",
    "\n",
    "# initialize the progress bar\n",
    "widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=len(imagePaths),widgets=widgets).start()\n",
    "\n",
    "# loop over the images in patches\n",
    "for i in np.arange(0, len(imagePaths), bs):\n",
    "    \n",
    "    batchPaths = imagePaths[i:i + bs]\n",
    "    batchLabels = labels[i:i + bs]\n",
    "    batchImages = []\n",
    "\n",
    "    # loop over the images and labels in the current batch\n",
    "    for (j, imagePath) in enumerate(batchPaths):\n",
    "        \n",
    "        # we resized all images to 224x224 pixels\n",
    "        image = load_img(imagePath, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = imagenet_utils.preprocess_input(image)\n",
    "        \n",
    "        # add the image to the batch\n",
    "        batchImages.append(image)\n",
    "\n",
    "    batchImages = np.vstack(batchImages)\n",
    "    features = model.predict(batchImages, batch_size=bs)\n",
    "\n",
    "    # reshape the features so that each image is represented by\n",
    "    # a flattened feature vector of the ‘MaxPooling2D‘ outputs\n",
    "    features = features.reshape((features.shape[0], 512 * 7 * 7))\n",
    "\n",
    "    # add the features and labels to our HDF5 dataset\n",
    "    dataset.add(features, batchLabels)\n",
    "    pbar.update(i)\n",
    "\n",
    "# close the dataset\n",
    "dataset.close()\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a-YJiUcfJk3"
   },
   "source": [
    "# Training an Orientation Correction Classifier\n",
    "\n",
    "**Here, we use Logistic Regression model for classification and tune the hyper parameter C using GridSearch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2-2GgCU-HVuG",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] tuning hyperparameters...\n",
      "[INFO] best hyperparameters: {'C': 1.0}\n",
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       615\n",
      "         180       0.92      0.93      0.92       627\n",
      "         270       0.89      0.89      0.89       622\n",
      "          90       0.90      0.91      0.91       631\n",
      "\n",
      "    accuracy                           0.91      2495\n",
      "   macro avg       0.91      0.91      0.91      2495\n",
      "weighted avg       0.91      0.91      0.91      2495\n",
      "\n",
      "[INFO] saving model...\n"
     ]
    }
   ],
   "source": [
    "# initialize hdf5 dataset path\n",
    "db=hdf5_path\n",
    "\n",
    "# open the HDF5 database for reading\n",
    "db = h5py.File(db, \"r\")\n",
    "i = int(db[\"labels\"].shape[0] * 0.75) # take 75% for training and rest for testing\n",
    "\n",
    "print(\"[INFO] tuning hyperparameters...\")\n",
    "params = {\"C\": [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]}\n",
    "\n",
    "model = GridSearchCV(LogisticRegression(max_iter=300), params, cv=3, n_jobs=1)\n",
    "model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n",
    "\n",
    "print(\"[INFO] best hyperparameters: {}\".format(model.best_params_))\n",
    "\n",
    "# evaluate the model\n",
    "print(\"[INFO] evaluating...\")\n",
    "preds = model.predict(db[\"features\"][i:])\n",
    "print(classification_report(db[\"labels\"][i:], preds,target_names=db[\"label_names\"]))\n",
    "\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving model...\")\n",
    "f = open(model_path, \"wb\")\n",
    "f.write(pickle.dumps(model.best_estimator_))\n",
    "f.close()\n",
    "\n",
    "# close the database\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciDBfTSqKUa1"
   },
   "source": [
    "# Pridicting some random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ggtFv925Kmit"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sampling images...\n",
      "[INFO] loading network...\n",
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "# initialize all paths\n",
    "db = hdf5_path\n",
    "model = model_path\n",
    "dataset = rotated_path\n",
    "\n",
    "# load the label names from the HDF5 dataset\n",
    "db = h5py.File(db)\n",
    "labelNames = [int(angle) for angle in db[\"label_names\"][:]]\n",
    "db.close()\n",
    "\n",
    "# grab the paths to the testing images and randomly sample them\n",
    "print(\"[INFO] sampling images...\")\n",
    "\n",
    "imagePaths = list(paths.list_images(dataset))\n",
    "imagePaths = np.random.choice(imagePaths, size=(10,), replace=False)\n",
    "\n",
    "# load the VGG16 network\n",
    "print(\"[INFO] loading network...\")\n",
    "vgg = VGGNet_16.build(weight_path)\n",
    "# vgg = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "\n",
    "# load the orientation model\n",
    "print(\"[INFO] loading model...\")\n",
    "model = pickle.loads(open(model, \"rb\").read())\n",
    "\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "\n",
    "    orig = cv2.imread(imagePath)\n",
    "\n",
    "    image = load_img(imagePath, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "    # pass the image through the network to obtain the feature vector\n",
    "    features = vgg.predict(image)\n",
    "    features = features.reshape((features.shape[0], 512 * 7 * 7))\n",
    "    # now that we have the CNN features, pass these through our\n",
    "    # classifier to obtain the orientation predictions\n",
    "    angle = model.predict(features)\n",
    "    angle = labelNames[angle[0]]\n",
    "    # now that we have the predicted orientation of the image we can\n",
    "    # correct for it\n",
    "    rotated = imutils.rotate_bound(orig, 360 - angle)\n",
    "    orig = cv2.resize(orig, (300,300))\n",
    "    rotated = cv2.resize(rotated, (300,300))\n",
    "    # display the original and corrected images\n",
    "    cv2.imshow(\"Original\", orig)\n",
    "    cv2.imshow(\"Corrected\", rotated)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CVPR-Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
